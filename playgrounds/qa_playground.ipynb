{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import os\n",
    "\n",
    "os.chdir(\"/app\")\n",
    "from langchain_community.chat_models import ChatHuggingFace\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "from apps.inners.use_cases.embeddings.bge_m3_embedding import BgeM3Embedding\n",
    "\n",
    "from apps.inners.use_cases.document_converters.libre_office_document_converter import LibreOfficeDocumentConverter\n",
    "from apps.inners.use_cases.document_converters.marker_document_converter import MarkerDocumentConverter\n",
    "from apps.inners.use_cases.graphs.long_form_qa_graph import LongFormQaGraph\n",
    "from apps.inners.use_cases.graphs.passage_search_graph import PassageSearchGraph\n",
    "from apps.inners.use_cases.long_form_qas.process_long_form_qa import ProcessLongFormQa\n",
    "from apps.inners.use_cases.managements.document_management import DocumentManagement\n",
    "from apps.inners.use_cases.managements.file_document_management import FileDocumentManagement\n",
    "from apps.inners.use_cases.managements.text_document_management import TextDocumentManagement\n",
    "from apps.inners.use_cases.managements.web_document_management import WebDocumentManagement\n",
    "from apps.inners.use_cases.passage_searches.process_passage_search import ProcessPassageSearch\n",
    "from apps.outers.datastores.four_datastore import FourDatastore\n",
    "from apps.outers.datastores.one_datastore import OneDatastore\n",
    "from apps.outers.datastores.temp_datastore import TempDatastore\n",
    "from apps.outers.datastores.three_datastore import ThreeDatastore\n",
    "from apps.outers.datastores.two_datastore import TwoDatastore\n",
    "from apps.outers.repositories.file_document_repository import FileDocumentRepository\n",
    "from apps.outers.repositories.text_document_repository import TextDocumentRepository\n",
    "from apps.outers.repositories.web_document_repository import WebDocumentRepository\n",
    "from apps.outers.settings.one_embedding_setting import OneEmbeddingSetting\n",
    "from apps.outers.settings.one_llm_setting import OneLlmSetting\n",
    "from tests.seeders.all_seeder import AllSeeder\n",
    "\n",
    "from apps.inners.models.dtos.contracts.requests.long_form_qas.input_setting_body import GeneratorSetting\n",
    "\n",
    "from apps.inners.models.dtos.contracts.requests.long_form_qas.input_setting_body import \\\n",
    "    InputSettingBody as LongFormQaInputSettingBody\n",
    "from apps.inners.models.dtos.contracts.requests.passage_searches.input_setting_body import \\\n",
    "    InputSettingBody as PassageSearchInputSettingBody, LlmSetting, \\\n",
    "    PreprocessorSetting, EmbedderSetting, RetrieverSetting, RerankerSetting\n",
    "from apps.inners.models.dtos.contracts.requests.passage_searches.process_body import \\\n",
    "    ProcessBody as PassageSearchProcessBody\n",
    "from apps.inners.models.dtos.contracts.requests.long_form_qas.process_body import ProcessBody as LongFormQaProcessBody\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from ragas.testset import TestsetGenerator, evolutions\n",
    "\n",
    "from apps.inners.use_cases.graphs.preparation_graph import PreparationGraph\n",
    "from apps.inners.use_cases.document_processor.category_document_processor import CategoryDocumentProcessor\n",
    "from apps.inners.use_cases.document_processor.partition_document_processor import PartitionDocumentProcessor\n",
    "from apps.inners.use_cases.document_processor.summary_document_processor import SummaryDocumentProcessor\n",
    "\n",
    "from tools import cache_tool\n",
    "\n",
    "import gc\n",
    "\n",
    "from starlette.datastructures import State\n",
    "\n",
    "import dotenv\n",
    "from datasets import load_dataset\n",
    "from dotenv import find_dotenv\n",
    "from ragas import evaluate, metrics\n",
    "\n",
    "from tests.containers.test_container import TestContainer\n",
    "from apps.inners.models.dtos.graph_state import LongFormQaGraphState, PreparationGraphState\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T22:16:42.743691Z",
     "start_time": "2024-05-05T22:16:34.598605Z"
    }
   },
   "id": "ccc0387222ff1e05",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T20:02:47.195990Z",
     "start_time": "2024-05-19T20:02:45.194750Z"
    }
   },
   "cell_type": "code",
   "source": "!pip show pytest",
   "id": "2bcb419739cf881c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pytest\r\n",
      "Version: 8.2.1\r\n",
      "Summary: pytest: simple powerful testing with Python\r\n",
      "Home-page: \r\n",
      "Author: Holger Krekel, Bruno Oliveira, Ronny Pfannschmidt, Floris Bruynooghe, Brianna Laugher, Florian Bruhin, Others (See AUTHORS)\r\n",
      "Author-email: \r\n",
      "License: MIT\r\n",
      "Location: /usr/local/lib/python3.10/dist-packages\r\n",
      "Requires: exceptiongroup, iniconfig, packaging, pluggy, tomli\r\n",
      "Required-by: pytest-asyncio, pytest-cov, pytest-xdist\r\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": "!python3 -m pytest --cov=./apps --cov-report=html ./tests -n 1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T22:48:07.220757Z",
     "start_time": "2024-05-05T22:45:31.347390Z"
    }
   },
   "id": "db1768c634143532",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# !pip show flagembedding\n",
    "# !pip show langchain-anthropic\n",
    "# !pip show pymilvus\n",
    "# !pip show opencv-python\n",
    "# !libreoffice --help\n",
    "# !wkhtmltopdf\n",
    "# !apt install strace\n",
    "# !strace -e open,openat python3 -c \"import tensorflow as tf\" 2>&1 | grep \"libnvinfer\\|TF-TRT\"\n",
    "# !echo $(echo $(dirname $(dirname $(python3 -c \"import nvidia.cudnn;print(nvidia.cudnn.__file__)\")))/*/lib/ | sed -r 's/\\s+/:/g')${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n",
    "# !ls /TensorRT-8.6.1.6\n",
    "# !python3 -m langchain_core.sys_info\n",
    "!pip show onnxruntime-gpu"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T17:50:42.124410Z",
     "start_time": "2024-06-14T17:50:40.148025Z"
    }
   },
   "id": "957c9e34eeb62d59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: onnxruntime-gpu\r\n",
      "Version: 1.17.0\r\n",
      "Summary: ONNX Runtime is a runtime accelerator for Machine Learning models\r\n",
      "Home-page: https://onnxruntime.ai\r\n",
      "Author: Microsoft Corporation\r\n",
      "Author-email: onnxruntime@microsoft.com\r\n",
      "License: MIT License\r\n",
      "Location: /usr/local/lib/python3.10/dist-packages\r\n",
      "Requires: coloredlogs, flatbuffers, numpy, packaging, protobuf, sympy\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T17:54:38.591693Z",
     "start_time": "2024-06-14T17:54:38.588410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from onnxruntime.capi import _pybind_state as C\n",
    "\n",
    "print(f\"Available ONNXRT providers: {C.get_available_providers()}\")"
   ],
   "id": "6dfecf26b6036b1b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available ONNXRT providers: ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow\n",
    "from tensorflow.compiler.tf2tensorrt._pywrap_py_utils import get_linked_tensorrt_version, get_loaded_tensorrt_version\n",
    "\n",
    "print(f\"Linked TensorRT version {get_linked_tensorrt_version()}\")\n",
    "print(f\"Loaded TensorRT version {get_loaded_tensorrt_version()}\")\n",
    "\n",
    "tensorflow.config.list_physical_devices('GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T17:33:20.704866Z",
     "start_time": "2024-06-14T17:33:20.700559Z"
    }
   },
   "id": "790b046202087813",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linked TensorRT version (8, 6, 1)\n",
      "Loaded TensorRT version (8, 6, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "# Sanity check if TensorRT is working.\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    # Create a simple model.\n",
    "    inputs = keras.Input(shape=(32,))\n",
    "    outputs = keras.layers.Dense(1)(inputs)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "# Train the model.\n",
    "test_input = np.random.random((128, 32))\n",
    "test_target = np.random.random((128, 1))\n",
    "model.fit(test_input, test_target)\n",
    "\n",
    "# Calling `save('my_model')` creates a SavedModel folder `my_model`.\n",
    "model.save(\"my_model.keras\")\n",
    "\n",
    "!aria2c https://raw.githubusercontent.com/tensorflow/tensorrt/master/tftrt/blog_posts/Leveraging%20TensorFlow-TensorRT%20integration%20for%20Low%20latency%20Inference/tf2_inference.py\n",
    "!python3 tf2_inference.py --use_tftrt_model --precision fp16"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T06:44:17.645331Z",
     "start_time": "2024-04-16T06:43:07.416084Z"
    }
   },
   "id": "5ba6aa9f8b2516df",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T15:03:45.962339Z",
     "start_time": "2024-04-14T15:03:45.958820Z"
    }
   },
   "id": "8638b0a2a9038acf",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dotenv.load_dotenv(find_dotenv())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T02:06:03.213795Z",
     "start_time": "2024-04-19T02:06:03.203613Z"
    }
   },
   "id": "f0a206c2ced40865",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_container: TestContainer = TestContainer()\n",
    "\n",
    "one_llm_setting: OneLlmSetting = test_container.applications.settings.one_llm()\n",
    "one_embedding_setting: OneEmbeddingSetting = test_container.applications.settings.one_embedding()\n",
    "\n",
    "one_datastore: OneDatastore = test_container.applications.datastores.one()\n",
    "two_datastore: TwoDatastore = test_container.applications.datastores.two()\n",
    "three_datastore: ThreeDatastore = test_container.applications.datastores.three()\n",
    "four_datastore: FourDatastore = test_container.applications.datastores.four()\n",
    "temp_datastore: TempDatastore = test_container.applications.datastores.temp()\n",
    "\n",
    "file_document_repository: FileDocumentRepository = test_container.applications.repositories.file_document()\n",
    "text_document_repository: TextDocumentRepository = test_container.applications.repositories.text_document()\n",
    "web_document_repository: WebDocumentRepository = test_container.applications.repositories.web_document()\n",
    "\n",
    "libre_office_document_converter: LibreOfficeDocumentConverter = test_container.applications.use_cases.document_converter.libre_office()\n",
    "marker_document_converter: MarkerDocumentConverter = test_container.applications.use_cases.document_converter.marker()\n",
    "document_management: DocumentManagement = test_container.applications.use_cases.managements.document()\n",
    "file_document_management: FileDocumentManagement = test_container.applications.use_cases.managements.file_document()\n",
    "text_document_management: TextDocumentManagement = test_container.applications.use_cases.managements.text_document()\n",
    "web_document_management: WebDocumentManagement = test_container.applications.use_cases.managements.web_document()\n",
    "\n",
    "long_form_qa_graph: LongFormQaGraph = test_container.applications.use_cases.graphs.long_form_qa()\n",
    "passage_search_graph: PassageSearchGraph = test_container.applications.use_cases.graphs.passage_search()\n",
    "\n",
    "process_passage_search: ProcessPassageSearch = test_container.applications.use_cases.passage_searches.process()\n",
    "process_long_form_qa: ProcessLongFormQa = test_container.applications.use_cases.long_form_qas.process()\n",
    "\n",
    "all_seeder: AllSeeder = test_container.seeders.all()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T21:42:55.289627Z",
     "start_time": "2024-05-05T21:42:55.130553Z"
    }
   },
   "id": "8eb9c2d30510de79",
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "await all_seeder.up()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T21:42:55.833847Z",
     "start_time": "2024-05-05T21:42:55.304017Z"
    }
   },
   "id": "1cf8b24205467927",
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "await all_seeder.down()",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T23:03:57.774814Z",
     "start_time": "2024-04-30T23:03:57.491472Z"
    }
   },
   "id": "d18db5f9358936e",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "await two_datastore.async_client.set(\"test\", \"test\", ex=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T21:50:48.726484Z",
     "start_time": "2024-03-22T21:50:48.718837Z"
    }
   },
   "id": "bf6d7b9a59665490",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "partition_document_processor: PartitionDocumentProcessor = PartitionDocumentProcessor(\n",
    "    document_management=document_management,\n",
    "    file_document_management=file_document_management,\n",
    "    text_document_management=text_document_management,\n",
    "    web_document_management=web_document_management,\n",
    ")\n",
    "\n",
    "summary_document_processor: SummaryDocumentProcessor = SummaryDocumentProcessor()\n",
    "category_document_processor: CategoryDocumentProcessor = CategoryDocumentProcessor(\n",
    "    summary_document_processor=summary_document_processor\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T20:52:49.961086Z",
     "start_time": "2024-05-01T20:52:49.958560Z"
    }
   },
   "id": "dd4988f2b8a6d69f",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "state = State()\n",
    "state.authorized_session = all_seeder.session_seeder.session_fake.data[0]\n",
    "state.session = one_datastore.get_session()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-05T21:42:57.413917Z",
     "start_time": "2024-05-05T21:42:57.411263Z"
    }
   },
   "id": "f956df7d2aed220c",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T21:42:57.636413Z",
     "start_time": "2024-05-05T21:42:57.624809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "from apps.inners.models.daos.document import Document\n",
    "from sqlalchemy import text, ScalarResult\n",
    "\n",
    "session = state.session\n",
    "await session.close()\n",
    "account_id: int = state.authorized_session.account_id\n",
    "filter: dict = {\n",
    "    \"name\": \"NAME1\",\n",
    "}\n",
    "size = 1000\n",
    "filter_expressions: List[str] = []\n",
    "for key, value in filter.items():\n",
    "    # filter_expressions.append(f\"account_document.{key}::text like '%{value}%'\")\n",
    "    filter_expressions.append(f\"SIMILARITY({key}::text, '{value}')\")\n",
    "query: str = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM document\n",
    "    WHERE account_id = '{account_id}'\n",
    "    ORDER BY (({'+'.join(filter_expressions)})/{len(filter_expressions)}) DESC\n",
    "    LIMIT {size};\n",
    "\"\"\"\n",
    "\n",
    "found_document_result: ScalarResult[Document] = await session.exec(\n",
    "    text(query)\n",
    ")\n",
    "found_documents: List[Document] = list(found_document_result.all())\n",
    "found_documents"
   ],
   "id": "e97c17149a4e935d",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# await state.session.rollback()\n",
    "# magic: Magic = Magic()\n",
    "# magic.from_buffer(\n",
    "#     all_seeder.file_document_seeder.file_document_fake.file_data[0]\n",
    "# )\n",
    "found_documents = await document_management.find_many_with_authorization_and_pagination(\n",
    "    state=state,\n",
    "    page_position=1,\n",
    "    page_size=1000\n",
    ")\n",
    "found_file_documents = await file_document_repository.find_many_by_id_and_account_id(\n",
    "    session=state.session,\n",
    "    ids=[found_document.id for found_document in found_documents],\n",
    "    account_id=state.authorized_session.account_id\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T14:46:56.933152Z",
     "start_time": "2024-04-15T14:46:56.913460Z"
    }
   },
   "id": "9a533ee7b1456875",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "found_documents\n",
    "found_file_documents"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-15T14:47:11.446884Z",
     "start_time": "2024-04-15T14:47:11.443374Z"
    }
   },
   "id": "8bf67f9417e17f3f",
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "passage_search_process_body = PassageSearchProcessBody(\n",
    "    input_setting=PassageSearchInputSettingBody(\n",
    "        document_ids=[\n",
    "            all_seeder.document_seeder.document_fake.data[0].id,\n",
    "            all_seeder.document_seeder.document_fake.data[1].id,\n",
    "            all_seeder.document_seeder.document_fake.data[2].id\n",
    "        ],\n",
    "        llm_setting=LlmSetting(\n",
    "            model_name=\"claude-3-haiku-20240307\",\n",
    "            max_token=500\n",
    "        ),\n",
    "        preprocessor_setting=PreprocessorSetting(\n",
    "            is_force_refresh_categorized_element=False,\n",
    "            is_force_refresh_categorized_document=False,\n",
    "            chunk_size=500,\n",
    "            overlap_size=50,\n",
    "            is_include_table=False,\n",
    "            is_include_image=False\n",
    "        ),\n",
    "        embedder_setting=EmbedderSetting(\n",
    "            is_force_refresh_embedding=False,\n",
    "            is_force_refresh_document=False,\n",
    "            model_name=\"BAAI/bge-m3\",\n",
    "            query_instruction=\"Given the question, retrieve passage that answer the question.\"\n",
    "        ),\n",
    "        retriever_setting=RetrieverSetting(\n",
    "            is_force_refresh_relevant_document=False,\n",
    "            top_k=50\n",
    "        ),\n",
    "        reranker_setting=RerankerSetting(\n",
    "            is_force_refresh_re_ranked_document=False,\n",
    "            model_name=\"BAAI/bge-reranker-v2-m3\",\n",
    "            top_k=5\n",
    "        ),\n",
    "        question=\"what is political science?\"\n",
    "    )\n",
    ")\n",
    "passage_search_process_response = await process_passage_search.process(\n",
    "    state=state,\n",
    "    body=passage_search_process_body\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T15:15:28.390549Z",
     "start_time": "2024-04-14T15:13:45.049651Z"
    }
   },
   "id": "687e6522f61bd267",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "passage_search_process_response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T15:15:28.397232Z",
     "start_time": "2024-04-14T15:15:28.391995Z"
    }
   },
   "id": "7a1730c301722caf",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "long_form_qa_process_body = LongFormQaProcessBody(\n",
    "    input_setting=LongFormQaInputSettingBody(\n",
    "        document_ids=[\n",
    "            all_seeder.document_seeder.document_fake.data[0].id,\n",
    "            all_seeder.document_seeder.document_fake.data[1].id,\n",
    "            all_seeder.document_seeder.document_fake.data[2].id\n",
    "        ],\n",
    "        llm_setting=LlmSetting(\n",
    "            model_name=\"claude-3-haiku-20240307\",\n",
    "            max_token=500\n",
    "        ),\n",
    "        preprocessor_setting=PreprocessorSetting(\n",
    "            is_force_refresh_categorized_element=False,\n",
    "            is_force_refresh_categorized_document=False,\n",
    "            chunk_size=500,\n",
    "            overlap_size=50,\n",
    "            is_include_table=False,\n",
    "            is_include_image=False\n",
    "        ),\n",
    "        embedder_setting=EmbedderSetting(\n",
    "            is_force_refresh_embedding=False,\n",
    "            is_force_refresh_document=False,\n",
    "            model_name=\"BAAI/bge-m3\",\n",
    "            query_instruction=\"Given the question, retrieve passage that answer the question.\"\n",
    "        ),\n",
    "        retriever_setting=RetrieverSetting(\n",
    "            is_force_refresh_relevant_document=False,\n",
    "            top_k=50\n",
    "        ),\n",
    "        reranker_setting=RerankerSetting(\n",
    "            is_force_refresh_re_ranked_document=False,\n",
    "            model_name=\"BAAI/bge-reranker-v2-m3\",\n",
    "            top_k=5\n",
    "        ),\n",
    "        question=\"what is political science?\",\n",
    "        generator_setting=GeneratorSetting(\n",
    "            is_force_refresh_generated_answer=False,\n",
    "            is_force_refresh_generated_question=False,\n",
    "            is_force_refresh_generated_hallucination_grade_hash=False,\n",
    "            is_force_refresh_generated_answer_relevancy_grade_hash=False,\n",
    "            prompt=\"\"\"Instruction: Create a concise and informative answer for a given question based solely on the given passages. You must only use information from the given passages. Use an academic style. Do not repeat text. Cite at least one passage in each sentence. Cite the passages using passage number notation like \"[number]\". If multiple passages contain the answer, cite those passages like \"[number, number, etc.]\". If the passages do not contain the answer to the question, then say that answering is impossible given the available information with the explanation. Ensure the output is not re-explaining the instruction.\n",
    "            Passages:\n",
    "            {% for passage in passages %}\n",
    "            [{{ loop.index }}]={{ passage.page_content }}\n",
    "            {% endfor %}\n",
    "            Question: {{ question }}\n",
    "            Answer:\"\"\"\n",
    "        ),\n",
    "        transform_question_max_retry=3\n",
    "    )\n",
    ")\n",
    "long_form_qa_process_response = await process_long_form_qa.process(\n",
    "    state=state,\n",
    "    body=long_form_qa_process_body\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T15:29:31.696688Z",
     "start_time": "2024-04-14T15:29:06.475280Z"
    }
   },
   "id": "17360727f94c7531",
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "long_form_qa_process_response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T15:57:12.730765Z",
     "start_time": "2024-04-14T15:57:12.727756Z"
    }
   },
   "id": "7a99c395fdbf38f5",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "converted_document_data = await libre_office_document_converter.convert(\n",
    "    state=state,\n",
    "    document_id=all_seeder.document_seeder.document_fake.data[1].id,\n",
    "    output_format=\"pdf\"\n",
    ")\n",
    "marked_document_data = await marker_document_converter.convert(\n",
    "    input_file_data=converted_document_data,\n",
    "    highlights=[(\"label\", \"Political science\")]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T11:29:43.621524Z",
     "start_time": "2024-04-14T11:29:42.906550Z"
    }
   },
   "id": "daca14ca3ac02807",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "elements = await partition_document_processor.partition(\n",
    "    state=state,\n",
    "    document_id=all_seeder.document_seeder.document_fake.data[0].id,\n",
    "    file_partition_strategy=\"auto\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T20:56:03.398127Z",
     "start_time": "2024-05-01T20:53:03.007888Z"
    }
   },
   "id": "a0da31259df77765",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "categorized_elements = await category_document_processor.categorize_elements(\n",
    "    elements=elements\n",
    ")\n",
    "categorized_elements.texts = categorized_elements.texts[:]\n",
    "categorized_documents = await category_document_processor.get_categorized_documents(\n",
    "    categorized_elements=categorized_elements,\n",
    "    summarization_model=ChatAnthropic(\n",
    "        anthropic_api_key=one_llm_setting.LLM_ONE_ANTHROPIC_API_KEY_ONE,\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=100,\n",
    "        streaming=True,\n",
    "        temperature=0\n",
    "    ),\n",
    "    is_include_table=False,\n",
    "    is_include_image=False,\n",
    "    chunk_size=100,\n",
    "    overlap_size=50,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-01T20:56:03.681262Z",
     "start_time": "2024-05-01T20:56:03.399619Z"
    }
   },
   "id": "10afce5f544ba8eb",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T21:14:36.139672Z",
     "start_time": "2024-05-01T21:14:36.108176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from apps.inners.models.dtos.document_category import DocumentCategory\n",
    "import uuid\n",
    "from unstructured.chunking.basic import chunk_elements\n",
    "from unstructured.documents.elements import Element\n",
    "from typing import Dict, Any, Tuple, List\n",
    "import more_itertools\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "chunk_size: int = 400\n",
    "overlap_size: int = 50\n",
    "separators: Tuple[str, ...] = (\"\\n\", \" \")\n",
    "id_key: str = \"id\"\n",
    "document_category: DocumentCategory = DocumentCategory(\n",
    "    texts=[],\n",
    "    tables=[],\n",
    "    images=[],\n",
    "    id_key=id_key\n",
    ")\n",
    "chunked_texts: List[Element] = chunk_elements(\n",
    "    elements=categorized_elements.texts,\n",
    "    include_orig_elements=True,\n",
    "    max_characters=chunk_size - overlap_size\n",
    ")\n",
    "for text_before, text_after in more_itertools.windowed(chunked_texts, n=2):\n",
    "    orig_elements: List[Element] = []\n",
    "    for orig_element in text_before.metadata.orig_elements + text_after.metadata.orig_elements:\n",
    "        if not any(orig_element.id == existing_orig_element.id for existing_orig_element in orig_elements):\n",
    "            orig_elements.append(orig_element)\n",
    "    orig_elements_metadata: Dict[str, Any] = {\n",
    "        \"origin_metadata\": [\n",
    "            orig_element.metadata.to_dict() for orig_element in orig_elements\n",
    "        ],\n",
    "        \"category\": \"text\"\n",
    "    }\n",
    "    last_index_of_separators: int = -1\n",
    "    for separator in separators:\n",
    "        last_index_of_separator = text_before.text.rfind(separator, 0, len(text_before.text) - overlap_size)\n",
    "        last_index_of_separators = max(last_index_of_separators, last_index_of_separator)\n",
    "\n",
    "    text = text_before.text[last_index_of_separators + 1:] + \" \" + text_after.text\n",
    "    document: Document = Document(\n",
    "        page_content=text,\n",
    "        metadata={\n",
    "            id_key: str(uuid.uuid4()),\n",
    "            **orig_elements_metadata,\n",
    "        }\n",
    "    )\n",
    "    document_category.texts.append(document)\n"
   ],
   "id": "415c09df38160423",
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T21:14:36.265561Z",
     "start_time": "2024-05-01T21:14:36.259462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_len = -1\n",
    "for document in document_category.texts:\n",
    "    print(document.page_content)\n",
    "    print()\n",
    "    max_len = max(max_len, len(document.page_content))\n",
    "\n",
    "max_len\n",
    "# for text in chunked_texts:\n",
    "#     print(text.text)\n",
    "#     print()\n",
    "    \n",
    "# len(chunked_texts)"
   ],
   "id": "1daccde56d1da88b",
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# cache_tool.clear_cache()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "cache_tool.get_cache()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b8b24852486963",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_state: PreparationGraphState = {\n",
    "    \"state\": state,\n",
    "    \"document_ids\": [\n",
    "        all_seeder.document_seeder.document_fake.data[0].id,\n",
    "        all_seeder.document_seeder.document_fake.data[1].id,\n",
    "        all_seeder.document_seeder.document_fake.data[2].id\n",
    "    ],\n",
    "    \"llm_setting\": {\n",
    "        \"model_name\": \"claude-3-haiku-20240307\",\n",
    "        \"max_token\": 500,\n",
    "        \"model\": None,\n",
    "    },\n",
    "    \"preprocessor_setting\": {\n",
    "        \"is_force_refresh_categorized_element\": False,\n",
    "        \"is_force_refresh_categorized_document\": False,\n",
    "        \"file_partition_strategy\": \"auto\",\n",
    "        \"chunk_size\": 500,\n",
    "        \"overlap_size\": 50,\n",
    "        \"is_include_table\": False,\n",
    "        \"is_include_image\": False,\n",
    "    },\n",
    "    \"categorized_element_hashes\": None,\n",
    "    \"categorized_documents\": None,\n",
    "    \"categorized_document_hashes\": None,\n",
    "}\n",
    "preparation_graph: PreparationGraph = PreparationGraph(\n",
    "    one_llm_setting=one_llm_setting,\n",
    "    two_datastore=two_datastore,\n",
    "    partition_document_processor=partition_document_processor,\n",
    "    category_document_processor=category_document_processor\n",
    ")\n",
    "output_state: PreparationGraphState = await preparation_graph.compiled_graph.ainvoke(\n",
    "    input=input_state\n",
    ")\n",
    "\n",
    "output_state"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T01:05:39.460586Z",
     "start_time": "2024-04-27T01:04:36.213921Z"
    }
   },
   "id": "a2f5592244e88285",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_name = \"SeaLLMs/SeaLLM-7B-v2.5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name,\n",
    ")\n",
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=8192,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "chat_llm = ChatHuggingFace(\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "generator_llm = chat_llm\n",
    "critic_llm = chat_llm\n",
    "\n",
    "# generator_llm = ChatAnthropic(\n",
    "#     model=\"claude-3-haiku-20240307\",\n",
    "#     anthropic_api_key=one_llm_setting.LLM_ONE_ANTHROPIC_API_KEY_ONE\n",
    "# )\n",
    "# critic_llm = ChatAnthropic(\n",
    "#     model=\"claude-3-opus-20240229\",\n",
    "#     anthropic_api_key=one_llm_setting.LLM_ONE_ANTHROPIC_API_KEY_ONE\n",
    "# )\n",
    "embeddings = BgeM3Embedding(\n",
    "    use_fp16=False,\n",
    "    normalize_embeddings=False,\n",
    "    return_colbert_vecs=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-27T01:49:16.949145Z"
    }
   },
   "id": "e46ff4943c608efd",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm=generator_llm,\n",
    "    critic_llm=critic_llm,\n",
    "    embeddings=embeddings\n",
    ")\n",
    "\n",
    "document_id = input_state[\"document_ids\"][0]\n",
    "document_category = output_state[\"categorized_documents\"][document_id]\n",
    "documents = document_category.get_all()\n",
    "test_set = generator.generate_with_langchain_docs(\n",
    "    documents=documents,\n",
    "    test_size=1,\n",
    "    distributions={\n",
    "        evolutions.simple: 0.5,\n",
    "        evolutions.reasoning: 0.25,\n",
    "        evolutions.multi_context: 0.25\n",
    "    }\n",
    ")"
   ],
   "id": "1bb2f046e042d12a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "eval_set = test_set.to_dataset()\n",
    "eval_set.rename_column(\n",
    "    original_column_name=\"answer\",\n",
    "    new_column_name=\"ground_truth\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T11:53:44.200286Z",
     "start_time": "2024-04-07T11:53:44.173502Z"
    }
   },
   "id": "ba3ab5a1d48e9b10",
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for index, eval in enumerate(eval_set):\n",
    "    state: State = State()\n",
    "    state.authorized_session = all_seeder.session_seeder.session_fake.data[0]\n",
    "    state.session = one_datastore.get_session()\n",
    "    input_state: LongFormQaGraphState = {\n",
    "        \"state\": state,\n",
    "        \"document_ids\": [\n",
    "            # all_seeder.document_seeder.document_fake.data[0].id,\n",
    "            all_seeder.document_seeder.document_fake.data[1].id,\n",
    "            all_seeder.document_seeder.document_fake.data[2].id\n",
    "        ],\n",
    "        \"llm_setting\": {\n",
    "            \"model_name\": \"claude-3-haiku-20240307\",\n",
    "            \"max_token\": 500,\n",
    "            \"model\": None,\n",
    "        },\n",
    "        \"preprocessor_setting\": {\n",
    "            \"is_force_refresh_categorized_element\": False,\n",
    "            \"is_force_refresh_categorized_document\": False,\n",
    "            \"chunk_size\": 500,\n",
    "            \"overlap_size:\": 50,\n",
    "            \"is_include_table\": False,\n",
    "            \"is_include_image\": False,\n",
    "        },\n",
    "        \"categorized_element_hashes\": None,\n",
    "        \"categorized_documents\": None,\n",
    "        \"categorized_document_hashes\": None,\n",
    "        \"next_document_id\": None,\n",
    "        \"embedder_setting\": {\n",
    "            \"is_force_refresh_embedding\": False,\n",
    "            \"is_force_refresh_document\": False,\n",
    "            # \"model_name\": \"intfloat/multilingual-e5-large-instruct\",\n",
    "            \"model_name\": \"BAAI/bge-m3\",\n",
    "            \"query_instruction\": \"Given the question, retrieve passage that answer the question.\",\n",
    "        },\n",
    "        \"retriever_setting\": {\n",
    "            \"is_force_refresh_relevant_document\": False,\n",
    "            \"top_k\": 50,\n",
    "        },\n",
    "        \"reranker_setting\": {\n",
    "            \"is_force_refresh_re_ranked_document\": False,\n",
    "            \"model_name\": \"BAAI/bge-reranker-v2-m3\",\n",
    "            \"top_k\": 5,\n",
    "        },\n",
    "        \"embedded_document_ids\": None,\n",
    "        \"next_categorized_document\": None,\n",
    "        \"relevant_documents\": None,\n",
    "        \"relevant_document_hash\": None,\n",
    "        \"re_ranked_documents\": None,\n",
    "        \"re_ranked_document_hash\": None,\n",
    "        \"question\": \"what is political science?\",\n",
    "        \"generator_setting\": {\n",
    "            \"is_force_refresh_generated_answer\": False,\n",
    "            \"is_force_refresh_generated_question\": False,\n",
    "            \"is_force_refresh_generated_hallucination_grade\": False,\n",
    "            \"is_force_refresh_generated_answer_relevancy_grade\": False,\n",
    "            \"prompt\": \"\"\"Instruction: Create a concise and informative answer for a given question based solely on the given passages. You must only use information from the given passages. Use an academic style. Do not repeat text. Cite at least one passage in each sentence. Cite the passages using passage number notation like \"[number]\". If multiple passages contain the answer, cite those passages like \"[number, number, etc.]\". If the passages do not contain the answer to the question, then say that answering is impossible given the available information with the explanation. Ensure the output is not re-explaining the instruction.\n",
    "            Passages:\n",
    "            {% for passage in passages %}\n",
    "            [{{ loop.index }}]={{ passage.page_content }}\n",
    "            {% endfor %}\n",
    "            Question: {{ question }}\n",
    "            Answer:\"\"\"\n",
    "        },\n",
    "        \"transform_question_max_retry\": 0,\n",
    "        \"generated_answer\": None,\n",
    "        \"generated_answer_hash\": None,\n",
    "        \"generated_question\": None,\n",
    "        \"generated_question_hash\": None,\n",
    "        \"generated_hallucination_grade\": None,\n",
    "        \"generated_hallucination_grade_hash\": None,\n",
    "        \"generated_answer_relevancy_grade\": None,\n",
    "        \"generated_answer_relevancy_grade_hash\": None,\n",
    "    }\n",
    "    output_state = await long_form_qa_graph.compiled_graph.ainvoke(input_state)\n",
    "\n",
    "    eval_set[index][\"contexts\"] = [document.page_content for document in\n",
    "                                   output_state[\"categorized_documents\"][document_id].get_all()]\n",
    "    eval_set[index][\"answer\"] = output_state[\"generated_answer\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T13:02:29.052327Z",
     "start_time": "2024-04-09T13:02:29.020593Z"
    }
   },
   "id": "b00a2eb40e471165",
   "execution_count": 166,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# loading the V2 dataset\n",
    "amnesty_qa = load_dataset(\"explodinggradients/amnesty_qa\", \"english_v2\", trust_remote_code=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T11:52:19.429367Z",
     "start_time": "2024-04-07T11:52:14.346712Z"
    }
   },
   "id": "2217646879776c61",
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "eval_set_2 = amnesty_qa[\"eval\"].select(range(1))\n",
    "eval_set_2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T11:52:19.435611Z",
     "start_time": "2024-04-07T11:52:19.430719Z"
    }
   },
   "id": "cfce79f2a5bad887",
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result = evaluate(\n",
    "    dataset=eval_set_2,\n",
    "    llm=critic_llm,\n",
    "    embeddings=embeddings,\n",
    "    metrics=[\n",
    "        metrics.faithfulness,\n",
    "        metrics.answer_relevancy,\n",
    "        metrics.context_recall,\n",
    "        metrics.context_precision,\n",
    "        #     metrics.answer_correctness,\n",
    "        #     metrics.context_relevancy,\n",
    "        #     metrics.context_entity_recall,\n",
    "    ],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T11:53:16.951693Z",
     "start_time": "2024-04-07T11:52:21.794628Z"
    }
   },
   "id": "994fa6d782998e85",
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T11:53:19.960416Z",
     "start_time": "2024-04-07T11:53:19.956876Z"
    }
   },
   "id": "a74f0707bbbb234c",
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7e9cf09a5e32f1",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
